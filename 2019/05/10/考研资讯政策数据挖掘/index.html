<!DOCTYPE html>
<html>
<head hexo-theme='https://volantis.js.org/#2.6.6'>
  <meta charset="utf-8">
  <!-- SEO相关 -->
  
    
  
  <!-- 渲染优化 -->
  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <meta name="HandheldFriendly" content="True" >
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <!-- 页面元数据 -->
  
    <title>考研咨询政策数据挖掘 - CyouGuang&#39;Blog</title>
  
    <meta name="keywords" content="Python,数据挖掘">
  
  
    <meta name="description" content="​    近年来，考研人数不断添加，考研对于我们来说是一个热点不断的话题，对于考研资讯信息不够集中，数据量过大，考生无法准确的判断某个时期热点的资料，因此越来越多考生想能够快速得了解考研资讯、国家政策以及院校政策。
​    本项目通过对招生资讯、国家政策、院校政策进行总体数据挖掘以及分别进行数据挖掘，对院校的资...">
  

  <!-- feed -->
  

  <!-- import meta -->
  

  <!-- link -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13/css/all.min.css">
  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css">

  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.css">

  

  

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer@1.10/dist/APlayer.min.css">
  

  

  <!-- import link -->
  

  
  
    
<link rel="stylesheet" href="/css/style.css">

  

  <script>
    function setLoadingBarProgress(num) {
      document.getElementById('loading-bar').style.width=num+"%";
    }
  </script>

  
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script>
	setTimeout(function() {
	  let script = document.createElement('script');
	  script.src = "https://www.googletagmanager.com/gtag/js?id=UA-129569508-1";
	  script.defer=true;
	  document.body.appendChild(script);
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-129569508-1');
	}, 5000);
    </script>
  
  
</head>

<body>
  
  <div id="loading-bar-wrapper">
  <div id="loading-bar"></div>
</div>
<header class="l_header shadow blur">
  <div class='container'>
  <div class='wrapper'>
    <div class='nav-sub'>
      <p class="title"></p>
      <ul class='switcher nav-list-h'>
        <li><a class="s-comment fas fa-comments fa-fw" target="_self" href='javascript:void(0)'></a></li>
        
          <li><a class="s-toc fas fa-list fa-fw" target="_self" href='javascript:void(0)'></a></li>
        
      </ul>
    </div>
		<div class="nav-main">
      
        
        <a class="title flat-box" target="_self" href='/'>
          
          
          
            blog
          
          
        </a>
      

			<div class='menu navigation'>
				<ul class='nav-list-h'>
          
          
          
            
            
              <li>
                <a class="flat-box" href=/
                  
                  
                  
                    id="home"
                  >
                  <i class='fas fa-rss fa-fw'></i>博客
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="flat-box" href=/categories/
                  
                  
                  
                    id="categories"
                  >
                  <i class='fas fa-folder-open fa-fw'></i>分类
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="flat-box" href=/tags/
                  
                  
                  
                    id="tags"
                  >
                  <i class='fas fa-tags fa-fw'></i>标签
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="flat-box" href=/archives/
                  
                  
                  
                    id="archives"
                  >
                  <i class='fas fa-archive fa-fw'></i>归档
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="flat-box" href=/friends/
                  
                  
                  
                    id="friends"
                  >
                  <i class='fas fa-link fa-fw'></i>友链
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="flat-box" href=/about/
                  
                  
                  
                    id="about"
                  >
                  <i class='fas fa-info-circle fa-fw'></i>关于
                </a>
                
              </li>
            
          
          
				</ul>
			</div>

      <div class="m_search">
        <form name="searchform" class="form u-search-form">
          <i class="icon fas fa-search fa-fw"></i>
          <input type="text" class="input u-search-input" placeholder="Search..." />
        </form>
      </div>

			<ul class='switcher nav-list-h'>
				
					<li><a class="s-search fas fa-search fa-fw" target="_self" href='javascript:void(0)'></a></li>
				
				<li>
          <a class="s-menu fas fa-bars fa-fw" target="_self" href='javascript:void(0)'></a>
          <ul class="menu-phone list-v navigation white-box">
            
              
            
              <li>
                <a class="flat-box" href=/
                  
                  
                  
                    id="home"
                  >
                  <i class='fas fa-rss fa-fw'></i>博客
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="flat-box" href=/categories/
                  
                  
                  
                    id="categories"
                  >
                  <i class='fas fa-folder-open fa-fw'></i>分类
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="flat-box" href=/tags/
                  
                  
                  
                    id="tags"
                  >
                  <i class='fas fa-tags fa-fw'></i>标签
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="flat-box" href=/archives/
                  
                  
                  
                    id="archives"
                  >
                  <i class='fas fa-archive fa-fw'></i>归档
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="flat-box" href=/friends/
                  
                  
                  
                    id="friends"
                  >
                  <i class='fas fa-link fa-fw'></i>友链
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="flat-box" href=/about/
                  
                  
                  
                    id="about"
                  >
                  <i class='fas fa-info-circle fa-fw'></i>关于
                </a>
                
              </li>
            
          
            
          </ul>
        </li>
			</ul>
		</div>
	</div>
  </div>
</header>

<script>setLoadingBarProgress(40);</script>



  <div class="l_body nocover">
    <div class='body-wrapper'>
      

<div class='l_main'>
  

  
    <article id="post" class="post white-box reveal shadow article-type-post" itemscope itemprop="blogPost">
      


  <section class='meta'>
    
      
      
      <div class="meta" id="header-meta">
        
          
  <h1 class="title">
    <a href="/2019/05/10/%E8%80%83%E7%A0%94%E8%B5%84%E8%AE%AF%E6%94%BF%E7%AD%96%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/">
      考研咨询政策数据挖掘
    </a>
  </h1>


        
        <div class='new-meta-box'>
          
            
          
            
              
<div class='new-meta-item author'>
  <a href="https://blog.chenyouguang.com" target="_blank" rel="nofollow noopener">
    <img src="https://cdn.jsdelivr.net/gh/sbtobb/CDN/blog/20200310235037.png">
    <p>CyouGuang</p>
  </a>
</div>

            
          
            
              
  
  <div class='new-meta-item category'>
    <a href='/categories/%E7%A0%94%E7%A9%B6%E9%A1%B9%E7%9B%AE/' rel="nofollow">
      <i class="fas fa-folder-open fa-fw" aria-hidden="true"></i>
      <p>Python/研究项目</p>
    </a>
  </div>


            
          
            
              <div class="new-meta-item date">
  <a class='notlink'>
    <i class="fas fa-calendar-alt fa-fw" aria-hidden="true"></i>
    <p>发布于：May 10, 2019</p>
  </a>
</div>

            
          
            
              

            
          
        </div>
        
          <hr>
        
      </div>
    
  </section>


      <section class="article typo">
        <div class="article-entry" itemprop="articleBody">
          
          <p>​    近年来，考研人数不断添加，考研对于我们来说是一个热点不断的话题，对于考研资讯信息不够集中，数据量过大，考生无法准确的判断某个时期热点的资料，因此越来越多考生想能够快速得了解考研资讯、国家政策以及院校政策。</p>
<p>​    本项目通过对招生资讯、国家政策、院校政策进行总体数据挖掘以及分别进行数据挖掘，对院校的资讯热点进行提取绘制成词云图。</p>
<p>​    考生通过数据绘制出词云图，可以清楚的了解到近年来院校关注的重点是什么，以及近年来考研相关的国家政策热点，借助这些信息，能够帮助到我们广大考生进行更好选择所需要关注的热点信息，更为方便的了解到国家政策。</p>
<a id="more"></a>
<h2 id="1-研究背景及目的"><a href="#1-研究背景及目的" class="headerlink" title="1 研究背景及目的"></a>1 研究背景及目的</h2><h3 id="1-1-背景"><a href="#1-1-背景" class="headerlink" title="1.1 背景"></a>1.1 背景</h3><p>​    近年来，考研人数不断添加，考研对于我们来说是一个热点不断的话题，对于考研资讯信息不够集中，数据量过大，考生无法准确的判断某个时期热点的资料，因此越来越多考生想能够快速得了解考研资讯、国家政策以及院校政策。</p>
<h3 id="1-2-考研资讯政策数据资源"><a href="#1-2-考研资讯政策数据资源" class="headerlink" title="1.2 考研资讯政策数据资源"></a>1.2 考研资讯政策数据资源</h3><p>(1)<strong>数据来源</strong></p>
<p><a href="https://yz.chsi.com.cn/" target="_blank" rel="noopener">中国研究生招生信息网</a></p>
<p>(2)<strong>数据规模</strong></p>
<p>爬取了近 5 年的招生资讯、国家政策、院校政策，共 5600 篇文章，约 750 万字。</p>
<p>(3)<strong>数据特征分析</strong></p>
<p>文本型数据，招生资讯占比 62%，国家政策占比 4%，院校政策占比 34%。</p>
<h3 id="1-3-考研资讯政策数据挖掘目的和意义"><a href="#1-3-考研资讯政策数据挖掘目的和意义" class="headerlink" title="1.3 考研资讯政策数据挖掘目的和意义"></a>1.3 考研资讯政策数据挖掘目的和意义</h3><p>(1)<strong>数据挖掘的目标</strong></p>
<p>​    通过对招生资讯、国家政策、院校政策进行总体数据挖掘以及分别进行数据挖掘，对 院校的资讯热点进行提取绘制成词云图。</p>
<p>(2)<strong>实际应用价值分析</strong></p>
<p>​    考生通过数据绘制出词云图，可以清楚的了解到近年来院校关注的重点是什么，以及近年来考研相关的国家政策热点，借助这些信息，能够帮助到我们广大考生进行更好选择所需要关注的热点信息，更为方便的了解到国家政策。</p>
<h2 id="2-考研资讯政策数据挖掘系统设计"><a href="#2-考研资讯政策数据挖掘系统设计" class="headerlink" title="2 考研资讯政策数据挖掘系统设计"></a>2 考研资讯政策数据挖掘系统设计</h2><h3 id="2-1-系统总体设计"><a href="#2-1-系统总体设计" class="headerlink" title="2.1 系统总体设计"></a>2.1 系统总体设计</h3><h4 id="2-1-1-系统设计目标"><a href="#2-1-1-系统设计目标" class="headerlink" title="2.1.1 系统设计目标"></a>2.1.1 系统设计目标</h4><p>​    通过爬虫爬取信息，将信息按照规定格式进行存储，将数据读入，构建语料库，进行中文分词，再进行词频统计分析，绘制词云图和柱状图，进行保存。</p>
<h4 id="2-1-2-总体流程图"><a href="#2-1-2-总体流程图" class="headerlink" title="2.1.2 总体流程图"></a>2.1.2 总体流程图</h4><p><img src="https://cdn.jsdelivr.net/gh/sbtobb/CDN/blog/流程图.png" alt="图 2.1 总体流程图" style="zoom: 60%;" /></p>
<p>​    系统由爬虫子系统和数据挖掘子系统组成，流程</p>
<h3 id="2-2-系统功能模块设计"><a href="#2-2-系统功能模块设计" class="headerlink" title="2.2 系统功能模块设计"></a>2.2 系统功能模块设计</h3><h4 id="2-2-1-数据抓取模块设计"><a href="#2-2-1-数据抓取模块设计" class="headerlink" title="2.2.1 数据抓取模块设计"></a>2.2.1 数据抓取模块设计</h4><p>​    给予开始位置、模式，即可开始抓取到研招网的招生资讯、院校政策、国家政策</p>
<p>的列表。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">模块:requests, bs4</span><br><span class="line">函数:</span><br><span class="line">http 请求函数:requests.get(url) url:待获取网页源代码的 URL</span><br><span class="line">html 解析函数:bs4.BeautifulSoup(content,model) content:待解析的 html 文本，</span><br><span class="line">model:解释器</span><br></pre></td></tr></table></figure>
<h4 id="2-2-2-数据解析模块设计"><a href="#2-2-2-数据解析模块设计" class="headerlink" title="2.2.2 数据解析模块设计"></a>2.2.2 数据解析模块设计</h4><p>​    给予 url，即可开始解析网页中的文章数据。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">模块:requests, bs4</span><br><span class="line">函数:</span><br><span class="line">数据标签查找函数:BeautifulSoup.find(tag,id) tag:html 标签 id:过滤器</span><br></pre></td></tr></table></figure>
<h4 id="2-2-3-数据保存模块设计"><a href="#2-2-3-数据保存模块设计" class="headerlink" title="2.2.3 数据保存模块设计"></a>2.2.3 数据保存模块设计</h4><p>​    给予待保存数据、文件路径，将会将数据文件按格式保存在磁盘中</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">模块:os</span><br><span class="line">函数:</span><br><span class="line">打开文件函数 open(path, model) path:打开的文档路径 model:打开模式(wt 为写 入模式)</span><br><span class="line">写入数据函数:f.write(article) article:待写入的数据</span><br></pre></td></tr></table></figure>
<h4 id="2-2-4-数据导入模块设计"><a href="#2-2-4-数据导入模块设计" class="headerlink" title="2.2.4 数据导入模块设计"></a>2.2.4 数据导入模块设计</h4><p>​    遍历文件夹，将文本数据从文件夹中取出来，并分析出出文本时间、文本类型，</p>
<p>返回拥有多个返回值 filePaths,fileContents,dateTimes,Species 都为 list 类型。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">模块:os，codecs</span><br><span class="line">函数:</span><br><span class="line">文件遍历函数:os.walk(path) path:待遍历文件路径</span><br><span class="line">读取文件函数 codecs.open(filePath,&#39;r&#39;,&#39;utf-8&#39;) 文件路径 打开模式 文件编码</span><br></pre></td></tr></table></figure>
<h4 id="2-2-5-构建语料库模块设计"><a href="#2-2-5-构建语料库模块设计" class="headerlink" title="2.2.5 构建语料库模块设计"></a>2.2.5 构建语料库模块设计</h4><p>​    给予数据文件夹路径，调用数据导入模块，取得文件数据，构建语料库。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">模块: pandas</span><br><span class="line">函数:</span><br><span class="line">创建数据框函数:pandas.DataFrame(&#123;&#125;) 参数:字典类型</span><br></pre></td></tr></table></figure>
<h4 id="2-2-6-中文分词模块设计"><a href="#2-2-6-中文分词模块设计" class="headerlink" title="2.2.6 中文分词模块设计"></a>2.2.6 中文分词模块设计</h4><blockquote>
<p>TextRank 算法分析: 类似于 PageRank 的思想，将文本中的语法单元视作图中的 节点，如果两个语法单元存在一定语法关系，则这两个语法单元在图中就会有一条边 相互连接，通过一定的迭代次数，最终不同的节点会有不同的权重，权重高的语法单 元可以作为关键词。节点的权重不仅依赖于它的入度结点，还依赖于这些入度结点的 权重，入度结点越多，入度结点的权重越大，说明这个结点的权重越高。</p>
</blockquote>
<p>​    给予语料库，对语料库文本进行中文分词，由于数据量较大，采用多线程方式执</p>
<p>行。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">模块: concurrent, jieba numpy</span><br><span class="line">函数:</span><br><span class="line">线程池创建函数:ThreadPoolExecutor(max_workers) max_workers: 同时进行的线</span><br><span class="line">程个数</span><br><span class="line">等待线程完成函数:wait(all_task, return_when&#x3D;ALL_COMPLETED) all_task:线程</span><br><span class="line">池句柄 return_when:等待类型 ALL_COMPLETED 全部线程执行完毕</span><br><span class="line">读取 csv 数据函数:pandas.read_csv(path, encoding, index_col) path:路径, encoding:</span><br><span class="line">编码, index_col 序列 Textran:jieba.analyse.textrank(content,topK&#x3D;50,withWeight&#x3D;False,allowPOS&#x3D;(&#39;ns&#39;, &#39;n&#39;,</span><br><span class="line">&#39;vn&#39;, &#39;v&#39;)) content:待分割的文本</span><br></pre></td></tr></table></figure>
<h4 id="2-2-7-词频统计模块设计"><a href="#2-2-7-词频统计模块设计" class="headerlink" title="2.2.7 词频统计模块设计"></a>2.2.7 词频统计模块设计</h4><p>​    给予中文分词数据框、过滤词频，对分词的数据进行合并统计。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">模块: pandas</span><br><span class="line">函数:</span><br><span class="line">词频合并函数:segment_dataframe.groupby(&#39;word&#39;)[&#39;count&#39;].sum() 参数(’word’):抽 取 word 字段 [&#39;count&#39;].sum() 计算 count 数据的和</span><br><span class="line">排序函数:ser_word.sort_values(ascending&#x3D;False) ascending 是否为升序 元组转换函数:zip(a,b) 打包 a,b 为元组数据</span><br></pre></td></tr></table></figure>
<h2 id="3-系统实现"><a href="#3-系统实现" class="headerlink" title="3 系统实现"></a>3 系统实现</h2><h3 id="3-1-数据抓取"><a href="#3-1-数据抓取" class="headerlink" title="3.1 数据抓取"></a>3.1 数据抓取</h3><blockquote>
<p>向服务器发送请求-&gt;编码猜测-&gt;对 html 文档进行遍历-&gt;组合成 list 数据</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义获取资讯列表函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_consultant_list</span><span class="params">(start, model)</span>:</span></span><br><span class="line">    <span class="comment"># 返回结果</span></span><br><span class="line">    result = []</span><br><span class="line">    <span class="comment"># 发送http请求</span></span><br><span class="line">    response = requests.get(base_url + <span class="string">"/kyzx/"</span>+model+<span class="string">"/?start="</span> + str(start))</span><br><span class="line">    <span class="comment"># 判断是否请求成功</span></span><br><span class="line">    <span class="keyword">if</span> response.status_code != <span class="number">200</span>:</span><br><span class="line">        print(<span class="string">"get_consultant_list请求失败"</span>)</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line">    <span class="comment"># 设置相应数据的编码为猜测的编码</span></span><br><span class="line">    response.encoding = response.apparent_encoding</span><br><span class="line">    <span class="comment"># 使用BeautifulSoup进行煲汤 解析器为 html.parser</span></span><br><span class="line">    soup = bs4.BeautifulSoup(response.text, <span class="string">"html.parser"</span>)</span><br><span class="line">    <span class="comment"># 寻找标签 ul css:news-list 的子标签</span></span><br><span class="line">    liList = soup.find(<span class="string">"ul"</span>, class_=<span class="string">"news-list"</span>).children</span><br><span class="line">    <span class="comment"># 对li标签进行遍历</span></span><br><span class="line">    <span class="keyword">for</span> li <span class="keyword">in</span> liList:</span><br><span class="line">        <span class="comment"># 判断类型是否为Tag</span></span><br><span class="line">        <span class="keyword">if</span> isinstance(li, bs4.element.Tag):</span><br><span class="line">            e = []</span><br><span class="line">            <span class="comment"># 提取出文章日期信息</span></span><br><span class="line">            date = li.span.string</span><br><span class="line">            <span class="comment"># 提取出文章标题</span></span><br><span class="line">            title = li.a.string</span><br><span class="line">            <span class="comment"># 提取出文章网址</span></span><br><span class="line">            url = li.a[<span class="string">'href'</span>]</span><br><span class="line">            <span class="keyword">if</span> date <span class="keyword">is</span> <span class="keyword">None</span> <span class="keyword">or</span> title <span class="keyword">is</span> <span class="keyword">None</span> <span class="keyword">or</span> url <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            e.append(title)</span><br><span class="line">            e.append(url)</span><br><span class="line">            e.append(date)</span><br><span class="line">            result.append(e)</span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<p>​    运行结果无误</p>
<p>​    采用 requests 库构建 HTTP 请求，再使用 BeautifulSoup 库进行 html 解析，找到存放文章 url 的标签之后，对该标签进行遍历，并过滤掉无用的标签，最后再不断拆分 html 数据，组合成自己 的数据结构。</p>
<h3 id="3-2-数据解析"><a href="#3-2-数据解析" class="headerlink" title="3.2 数据解析"></a>3.2 数据解析</h3><blockquote>
<p>向服务器发送请求-&gt;编码猜测-&gt;对 html 文档进行解析-&gt;遍历 p 标签-&gt;组合 p 标签数据</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义获取文章函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_article</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="comment"># 发送http请求</span></span><br><span class="line">    response = requests.get(base_url + url)</span><br><span class="line">    <span class="comment"># 判断是否请求成功</span></span><br><span class="line">    <span class="keyword">if</span> response.status_code != <span class="number">200</span>:</span><br><span class="line">        print(<span class="string">"response 请求失败"</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">""</span></span><br><span class="line">    <span class="comment"># 设置相应数据的编码为猜测的编码</span></span><br><span class="line">    response.encoding = response.apparent_encoding</span><br><span class="line">    <span class="comment"># 使用BeautifulSoup进行煲汤 解析器为 html.parser</span></span><br><span class="line">    soup = bs4.BeautifulSoup(response.text, <span class="string">"html.parser"</span>)</span><br><span class="line">    <span class="comment"># 寻找标签 div id:article_dnull</span></span><br><span class="line">    div_element = soup.find(<span class="string">"div"</span>, id=<span class="string">"article_dnull"</span>)</span><br><span class="line">    result = <span class="string">""</span></span><br><span class="line">    <span class="comment"># 找到 div 标签下所有的p标签并进行遍历</span></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> div_element.findAll(<span class="string">"p"</span>):</span><br><span class="line">        <span class="keyword">if</span> p.string <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        result = result + p.string</span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<p>​    运行结果无误</p>
<p>​    分析:采用 requests 库构建 HTTP 请求，使用 BeautifulSoup 库进行 html 解析，定位到存放文章的 标签 div 上面，再对其下的 p 标签进行遍历，取出每一句的文章数据进行组合。</p>
<h3 id="3-3-数据保存"><a href="#3-3-数据保存" class="headerlink" title="3.3 数据保存"></a>3.3 数据保存</h3><blockquote>
<p>替换掉特殊字符-&gt;取出文章数据-&gt;判断文章是否为空-&gt;写入磁盘-&gt;打印 log</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义保存文章函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_article</span><span class="params">(l,path)</span>:</span></span><br><span class="line">    <span class="comment"># 替换掉标题中的特殊字符 避免不能保存</span></span><br><span class="line">    title = l[<span class="number">0</span>].replace(<span class="string">"："</span>, <span class="string">""</span>)</span><br><span class="line">    title = title.replace(<span class="string">":"</span>, <span class="string">""</span>)</span><br><span class="line">    title = title.replace(<span class="string">"/"</span>, <span class="string">""</span>)</span><br><span class="line">    totalPath = path + l[<span class="number">2</span>] + <span class="string">"-"</span> + title + <span class="string">".txt"</span></span><br><span class="line">    <span class="comment"># 取出文章数据</span></span><br><span class="line">    article = get_article(l[<span class="number">1</span>])</span><br><span class="line">    <span class="comment"># 判断文章是否为空</span></span><br><span class="line">    <span class="keyword">if</span> article == <span class="string">""</span>:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="comment"># 保存数据</span></span><br><span class="line">    <span class="keyword">with</span> open(totalPath, <span class="string">'wt'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(article)</span><br><span class="line">    <span class="comment"># 打印log</span></span><br><span class="line">    print(l[<span class="number">2</span>] + <span class="string">"-"</span> + l[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<p>​    分析:取出文章的标题信息，将标题信息的特殊字符过滤掉避免无法保存到计算机里，判断文章 数据是否为空值，写出文本文件。</p>
<h3 id="3-4-数据导入"><a href="#3-4-数据导入" class="headerlink" title="3.4 数据导入"></a>3.4 数据导入</h3><blockquote>
<p>遍历文件夹-&gt;截取时间元组-&gt;读入文本数据-&gt;判断文本类型-&gt;组合数据返回</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os;</span><br><span class="line"><span class="keyword">import</span> os.path;</span><br><span class="line"><span class="keyword">import</span> codecs;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">file_traversal</span><span class="params">(path)</span>:</span></span><br><span class="line">    <span class="string">"""遍历文件夹</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    遍历数据文件夹</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        path: 待遍历的文件路径</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        拥有多个返回值 filePaths,fileContents,dateTimes,Species</span></span><br><span class="line"><span class="string">        都为list类型</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 文件路径</span></span><br><span class="line">    filePaths = []</span><br><span class="line">    <span class="comment"># 文件内容</span></span><br><span class="line">    fileContents = []</span><br><span class="line">    <span class="comment"># 日期</span></span><br><span class="line">    years = []</span><br><span class="line">    months = []</span><br><span class="line">    days = []</span><br><span class="line">    <span class="comment"># 类别</span></span><br><span class="line">    Species=[]</span><br><span class="line">    <span class="keyword">for</span> root, dirs, files <span class="keyword">in</span> os.walk(path):</span><br><span class="line">        <span class="keyword">for</span> name <span class="keyword">in</span> files:</span><br><span class="line">            <span class="keyword">if</span> name == <span class="string">".DS_Store"</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="comment">#从文件名中截取出时间元组</span></span><br><span class="line">            time_str = name[:<span class="number">10</span>]</span><br><span class="line">            year = int(time_str[:<span class="number">4</span>])</span><br><span class="line">            month = int(time_str[<span class="number">5</span>:<span class="number">7</span>])</span><br><span class="line">            day = int(time_str[<span class="number">9</span>:<span class="number">11</span>])</span><br><span class="line">            filePath = os.path.join(root,name)</span><br><span class="line">            filePaths.append(filePath)</span><br><span class="line">            f = codecs.open(filePath,<span class="string">'r'</span>,<span class="string">'utf-8'</span>)</span><br><span class="line">            fileContent = f.read()</span><br><span class="line">            f.close()</span><br><span class="line">            years.append(year)</span><br><span class="line">            months.append(month)</span><br><span class="line">            days.append(day)</span><br><span class="line">            fileContents.append(fileContent)</span><br><span class="line">            <span class="keyword">if</span> root.find(<span class="string">'consultant'</span>) != <span class="number">-1</span>:</span><br><span class="line">                Species.append(<span class="string">'consultant'</span>)</span><br><span class="line">            <span class="keyword">elif</span> root.find(<span class="string">'countries_policy'</span>) != <span class="number">-1</span>:</span><br><span class="line">                Species.append(<span class="string">'countries_policy'</span>)</span><br><span class="line">            <span class="keyword">elif</span>  root.find(<span class="string">'school_policy'</span>) != <span class="number">-1</span>:</span><br><span class="line">                Species.append(<span class="string">'school_policy'</span>)</span><br><span class="line">            <span class="keyword">else</span> :</span><br><span class="line">                Species.append(<span class="string">'null'</span>)</span><br><span class="line">    <span class="keyword">return</span> filePaths,fileContents,Species,years,months,days</span><br></pre></td></tr></table></figure>
<p>​    运行结果无误</p>
<p>​    分析:采用 os.walk 进行文件遍历，使用 codecs.open 读入文本数据，分割出文章文本的发布时 间，通过文件路径名判断文本数据的类型</p>
<h3 id="3-5-数据预处理"><a href="#3-5-数据预处理" class="headerlink" title="3.5 数据预处理"></a>3.5 数据预处理</h3><blockquote>
<p>将数据读入的返回值构建成语料库</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_corpus</span><span class="params">(path)</span>:</span></span><br><span class="line">    <span class="string">"""构建语料库</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    构建语料库</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        path: 待遍历的文件路径</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">       DateFrame 语料库</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    filePaths,fileContents,Species,years,months,days = file_traversal(path)</span><br><span class="line">    <span class="comment"># 将filePath、fileContent、dateTime、Species 加载到数据框corpos中，形成语料库</span></span><br><span class="line"></span><br><span class="line">    corpos = pandas.DataFrame(&#123;</span><br><span class="line">        <span class="string">'filePath'</span>:filePaths,</span><br><span class="line">        <span class="string">'fileContent'</span>:fileContents,</span><br><span class="line">        <span class="string">'Species'</span>:Species,</span><br><span class="line">        <span class="string">'year'</span>:years,</span><br><span class="line">        <span class="string">'month'</span>:months,</span><br><span class="line">        <span class="string">'day'</span>:days</span><br><span class="line">    &#125;)</span><br><span class="line">    <span class="keyword">return</span> corpos</span><br></pre></td></tr></table></figure>
<p>​    运行结果无误</p>
<p>​    分析:将文件遍历的结构构建成语料库</p>
<h3 id="3-6-文本关键词模型的构建"><a href="#3-6-文本关键词模型的构建" class="headerlink" title="3.6 文本关键词模型的构建"></a>3.6 文本关键词模型的构建</h3><blockquote>
<p>创建线程池-&gt;遍历语料库-&gt;提交结巴分词任务-&gt;读入停用词-&gt;采用 TextRank 进行分词-&gt;等待线程结束-&gt;组合多线程函数结果</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">import</span> numpy</span><br><span class="line"><span class="keyword">import</span> jieba.analyse</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义结巴分词函数</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">jieba_segment</span><span class="params">(content)</span>:</span></span><br><span class="line">    <span class="string">"""结巴分词</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    对语料库文本进行中文分词</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        content: 待切割文本</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">       List [&#123;'word':a,'count',1&#125;] 分词列表</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># 分词词库</span></span><br><span class="line">    segments = []</span><br><span class="line">    <span class="comment"># 读入停用词</span></span><br><span class="line">    stopwords = pandas.read_csv(</span><br><span class="line">        <span class="string">"/Users/Apple/Documents/CodeWork/DataAnalysis/code_week_6/3.1/StopwordsCN.txt"</span>,</span><br><span class="line">        encoding=<span class="string">'utf8'</span>,</span><br><span class="line">        index_col=<span class="keyword">False</span></span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    words = jieba.analyse.textrank(content, topK=<span class="number">50</span>,withWeight=<span class="keyword">False</span>,allowPOS=(<span class="string">'ns'</span>, <span class="string">'n'</span>, <span class="string">'vn'</span>, <span class="string">'v'</span>))</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">        <span class="comment"># 记录全局分词</span></span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> stopwords:</span><br><span class="line">            segments.append(&#123;<span class="string">'word'</span>:word, <span class="string">'count'</span>:<span class="number">1</span>&#125;)</span><br><span class="line">    <span class="keyword">return</span> segments</span><br><span class="line">  </span><br><span class="line"> <span class="comment"># 定义中文分词函数</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> concurrent.futures <span class="keyword">import</span> ThreadPoolExecutor,wait,ALL_COMPLETED</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">word_segment</span><span class="params">(corpos)</span>:</span></span><br><span class="line">    <span class="string">"""中文分词</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    对语料库文本进行中文分词，由于数据量较大，采用多线程方式执行</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        corpos: 语料库</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">       DateFrame 词频</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># 创建线程池</span></span><br><span class="line">    executor = ThreadPoolExecutor(max_workers=<span class="number">20</span>)</span><br><span class="line">    <span class="comment"># 线程池句柄</span></span><br><span class="line">    all_task = []</span><br><span class="line">    <span class="comment"># 分词词库</span></span><br><span class="line">    segments = []</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> index, row <span class="keyword">in</span> corpos.iterrows():</span><br><span class="line">        content = row[<span class="string">'fileContent'</span>]</span><br><span class="line">        all_task.append(executor.submit(jieba_segment,content))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 等待线程全部完成</span></span><br><span class="line">    wait(all_task, return_when=ALL_COMPLETED)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 将结果汇总</span></span><br><span class="line">    <span class="keyword">for</span> task <span class="keyword">in</span> all_task:</span><br><span class="line">        segments.extend(task.result())</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 构建DateFrame</span></span><br><span class="line">    dfSg = pd.DataFrame(segments)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dfSg</span><br></pre></td></tr></table></figure>
<p>​    运行结果无误</p>
<p>​    分析:由于数据量过于庞大，单线程需要等待时间过久，这里采用多线程的方式进行文本分割， 建立线程池后，将待分割的文本数据传入结巴分词函数中，结巴分词采用 TextRank 算法进行文本 分割，等待文本分割完成后，再将数据组合。</p>
<h3 id="3-7-文本关键词模型的训练"><a href="#3-7-文本关键词模型的训练" class="headerlink" title="3.7 文本关键词模型的训练"></a>3.7 文本关键词模型的训练</h3><blockquote>
<p>词频统计:将分词进行聚合合并-&gt;降序排序-&gt;过滤数据-&gt;转换成元组数据</p>
<p>词云图生成:输入词频元组数据,标题，设置词云图参数，返回词云图对象</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义词频统计函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">word_frequency</span><span class="params">(segment_dataframe,count_filter = <span class="number">0</span>)</span>:</span></span><br><span class="line">    <span class="string">"""词频统计</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    对分词的数据进行合并统计</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        segment_dataframe: 中文分词</span></span><br><span class="line"><span class="string">        count_filter:排除小于过滤的词</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">       tuple 词频</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># 对分词进行合并</span></span><br><span class="line">    ser_word = segment_dataframe.groupby(<span class="string">'word'</span>)[<span class="string">'count'</span>].sum()</span><br><span class="line">    <span class="comment"># 对分词进行排序</span></span><br><span class="line">    nSegStat = ser_word.sort_values(ascending=<span class="keyword">False</span>)</span><br><span class="line">    <span class="comment"># 过滤</span></span><br><span class="line">    nSegStat = nSegStat[nSegStat &gt;= count_filter]</span><br><span class="line">    <span class="comment"># 转换成元组数据</span></span><br><span class="line">    tup = tuple(zip(nSegStat.index,nSegStat))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> tup</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 定义生成词云图函数</span></span><br><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> options <span class="keyword">as</span> opts</span><br><span class="line"><span class="keyword">from</span> pyecharts.charts <span class="keyword">import</span> Page, WordCloud</span><br><span class="line"><span class="keyword">from</span> pyecharts.globals <span class="keyword">import</span> SymbolType,CurrentConfig, NotebookType</span><br><span class="line">CurrentConfig.NOTEBOOK_TYPE = NotebookType.JUPYTER_LAB</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_word_cloud</span><span class="params">(data,title=<span class="string">""</span>)</span>:</span></span><br><span class="line">  word_cloud = (</span><br><span class="line">    WordCloud()</span><br><span class="line">    <span class="comment"># 添加数据和词云图的标题 字大小</span></span><br><span class="line">    .add(series_name=title, data_pair=data, word_size_range=[<span class="number">10</span>, <span class="number">100</span>])</span><br><span class="line">    <span class="comment"># 设置图片的参数</span></span><br><span class="line">    .set_global_opts(</span><br><span class="line">      title_opts=opts.TitleOpts(</span><br><span class="line">        title=title, title_textstyle_opts=opts.TextStyleOpts(font_size=<span class="number">23</span>)</span><br><span class="line">      ),</span><br><span class="line">      tooltip_opts=opts.TooltipOpts(is_show=<span class="keyword">True</span>),</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  <span class="keyword">return</span> word_cloud</span><br></pre></td></tr></table></figure>
<p>​    运行结果无误</p>
<p>​    分析:词频统计将分词数据使用聚合函数进行分类，使用 sort_values 进行降序排序，过滤掉过 小而无法显示的数据，提高词云图渲染的速度。</p>
<h2 id="4-系统测试分析"><a href="#4-系统测试分析" class="headerlink" title="4 系统测试分析"></a>4 系统测试分析</h2><h3 id="4-1-数据爬取"><a href="#4-1-数据爬取" class="headerlink" title="4.1 数据爬取"></a>4.1 数据爬取</h3><blockquote>
<p>创建线程池-&gt;设置抓取的资讯-&gt;获取数据列表-&gt;遍历数据列表-&gt;提交爬取文章任务</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建线程池</span></span><br><span class="line">executor = ThreadPoolExecutor(max_workers=<span class="number">20</span>)</span><br><span class="line"><span class="comment"># 开始位置</span></span><br><span class="line">start = <span class="number">0</span></span><br><span class="line">go_ahead = <span class="keyword">True</span></span><br><span class="line"><span class="comment"># 招生资讯:kydt  院校政策:yxzc 国家政策:zcdh</span></span><br><span class="line">model = <span class="string">"zcdh"</span></span><br><span class="line"></span><br><span class="line">file_path = <span class="string">""</span></span><br><span class="line"><span class="keyword">if</span> model == <span class="string">"kydt"</span>:</span><br><span class="line">    file_path = <span class="string">"consultant"</span></span><br><span class="line"><span class="keyword">elif</span> model == <span class="string">"yxzc"</span>:</span><br><span class="line">    file_path = <span class="string">"school_policy"</span></span><br><span class="line"><span class="keyword">elif</span> model == <span class="string">"zcdh"</span>:</span><br><span class="line">    file_path = <span class="string">"countries_policy"</span></span><br><span class="line"><span class="keyword">if</span> file_path == <span class="string">""</span>:</span><br><span class="line">    print(<span class="string">"请输入合理的爬虫参数"</span>)</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> go_ahead:</span><br><span class="line">    <span class="comment"># 获取50个数据列表</span></span><br><span class="line">    clist = get_consultant_list(start,model)</span><br><span class="line">    <span class="comment"># 线程句柄保存</span></span><br><span class="line">    all_task = []</span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> clist:</span><br><span class="line">        <span class="comment"># 读取年份数据</span></span><br><span class="line">        year = (l[<span class="number">2</span>])[:<span class="number">4</span>]</span><br><span class="line">        <span class="keyword">if</span> year == <span class="string">"2012"</span>:</span><br><span class="line">            go_ahead = <span class="keyword">False</span></span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="comment"># 数据分类分年存放</span></span><br><span class="line">        path = os.getcwd()+<span class="string">'/'</span>+file_path+<span class="string">'/'</span>+year+<span class="string">"/"</span></span><br><span class="line">        <span class="comment"># 判断文件夹是否存在 不存在创建一个新的文件夹</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(path):</span><br><span class="line">            os.makedirs(path)</span><br><span class="line">        <span class="comment"># 将获取数据函数加入线程池</span></span><br><span class="line">        all_task.append(executor.submit(save_article,l,path))</span><br><span class="line">    <span class="comment"># 等待所有线程完成</span></span><br><span class="line">    wait(all_task, return_when=ALL_COMPLETED)</span><br><span class="line">    <span class="comment"># 进行下一个开始位置</span></span><br><span class="line">    start = start + <span class="number">50</span></span><br></pre></td></tr></table></figure>
<p>​    分析:数据量过大且 HTTP 请求需要时间，采用了多线程的方式爬取数据，并将数据按照规定的</p>
<p>格式进行保存，方便数据读入分析。</p>
<h3 id="4-2-总体分析"><a href="#4-2-总体分析" class="headerlink" title="4.2 总体分析"></a>4.2 总体分析</h3><blockquote>
<p>将数据文件夹传入-&gt;构建语料库-&gt;创建中文分词-&gt;将词频低于 150 次的词过滤，提高词云图的</p>
<p>渲染速度-&gt;创建词云图-&gt;保存图片</p>
</blockquote>
<p><img src="https://cdn.jsdelivr.net/gh/sbtobb/CDN/blog/总体分析代码图.png" alt="总体分析代码图"></p>
<p><img src="https://cdn.jsdelivr.net/gh/sbtobb/CDN/blog/OverallAnalysis.png" alt="OverallAnalysis"></p>
<p><img src="https://cdn.jsdelivr.net/gh/sbtobb/CDN/blog/OverallConsultant.png" alt="OverallConsultant"></p>
<p><img src="https://cdn.jsdelivr.net/gh/sbtobb/CDN/blog/OverallCountriesPolicy.png" alt="OverallCountriesPolicy"></p>
<p><img src="https://cdn.jsdelivr.net/gh/sbtobb/CDN/blog/OverallSchoolPolicy.png" alt="OverallSchoolPolicy"></p>

          
            <div class='article_footer'>
              
                
  
    
    



  

  
    
    



  

  
    
    

<section class="widget copyright  desktop mobile">
  <div class='content'>
    
      <blockquote>
        
          
            <p>博客内容遵循 署名-非商业性使用-相同方式共享 4.0 国际 (CC BY-NC-SA 4.0) 协议</p>

          
        
          
            <p>本文永久链接是：<a href=https://blog.chenyouguang.cn/2019/05/10/%E8%80%83%E7%A0%94%E8%B5%84%E8%AE%AF%E6%94%BF%E7%AD%96%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/>https://blog.chenyouguang.cn/2019/05/10/%E8%80%83%E7%A0%94%E8%B5%84%E8%AE%AF%E6%94%BF%E7%AD%96%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/</a></p>
          
        
      </blockquote>
    
  </div>
</section>

  


              
            </div>
          
        </div>
        
          


  <section class='meta' id="footer-meta">
    <div class='new-meta-box'>
      
        
          <div class="new-meta-item date" itemprop="dateUpdated" datetime="2020-06-28T11:23:19+00:00">
  <a class='notlink'>
    <i class="fas fa-edit fa-fw" aria-hidden="true"></i>
    <p>更新于：Jun 28, 2020</p>
  </a>
</div>

        
      
        
          
  
  <div class="new-meta-item meta-tags"><a class="tag" href="/tags/Python/" rel="nofollow"><i class="fas fa-hashtag fa-fw" aria-hidden="true"></i><p>Python</p></a></div> <div class="new-meta-item meta-tags"><a class="tag" href="/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/" rel="nofollow"><i class="fas fa-hashtag fa-fw" aria-hidden="true"></i><p>数据挖掘</p></a></div>


        
      
        
          

        
      
        
          
  <div class="new-meta-item share -mob-share-list">
  <div class="-mob-share-list share-body">
    
      
        <a class="-mob-share-qq" title="" rel="external nofollow noopener noreferrer"
          
          href="http://connect.qq.com/widget/shareqq/index.html?url=https://blog.chenyouguang.cn/2019/05/10/%E8%80%83%E7%A0%94%E8%B5%84%E8%AE%AF%E6%94%BF%E7%AD%96%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/&title=考研咨询政策数据挖掘 - CyouGuang'Blog&summary=​    近年来，考研人数不断添加，考研对于我们来说是一个热点不断的话题，对于考研资讯信息不够集中，数据量过大，考生无法准确的判断某个时期热点的资料，因此越来越多考生想能够快速得了解考研资讯、国家政策以及院校政策。
​    本项目通过对招生资讯、国家政策、院校政策进行总体数据挖掘以及分别进行数据挖掘，对院校的资讯热点进行提取绘制成词云图。
​    考生通过数据绘制出词云图，可以清楚的了解到近年来院校关注的重点是什么，以及近年来考研相关的国家政策热点，借助这些信息，能够帮助到我们广大考生进行更好选择所需要关注的热点信息，更为方便的了解到国家政策。"
          
          >
          
            <img src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/logo/128/qq.png">
          
        </a>
      
    
      
        <a class="-mob-share-qzone" title="" rel="external nofollow noopener noreferrer"
          
          href="https://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url=https://blog.chenyouguang.cn/2019/05/10/%E8%80%83%E7%A0%94%E8%B5%84%E8%AE%AF%E6%94%BF%E7%AD%96%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/&title=考研咨询政策数据挖掘 - CyouGuang'Blog&summary=​    近年来，考研人数不断添加，考研对于我们来说是一个热点不断的话题，对于考研资讯信息不够集中，数据量过大，考生无法准确的判断某个时期热点的资料，因此越来越多考生想能够快速得了解考研资讯、国家政策以及院校政策。
​    本项目通过对招生资讯、国家政策、院校政策进行总体数据挖掘以及分别进行数据挖掘，对院校的资讯热点进行提取绘制成词云图。
​    考生通过数据绘制出词云图，可以清楚的了解到近年来院校关注的重点是什么，以及近年来考研相关的国家政策热点，借助这些信息，能够帮助到我们广大考生进行更好选择所需要关注的热点信息，更为方便的了解到国家政策。"
          
          >
          
            <img src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/logo/128/qzone.png">
          
        </a>
      
    
      
        <a class="-mob-share-weibo" title="" rel="external nofollow noopener noreferrer"
          
          href="http://service.weibo.com/share/share.php?url=https://blog.chenyouguang.cn/2019/05/10/%E8%80%83%E7%A0%94%E8%B5%84%E8%AE%AF%E6%94%BF%E7%AD%96%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/&title=考研咨询政策数据挖掘 - CyouGuang'Blog&summary=​    近年来，考研人数不断添加，考研对于我们来说是一个热点不断的话题，对于考研资讯信息不够集中，数据量过大，考生无法准确的判断某个时期热点的资料，因此越来越多考生想能够快速得了解考研资讯、国家政策以及院校政策。
​    本项目通过对招生资讯、国家政策、院校政策进行总体数据挖掘以及分别进行数据挖掘，对院校的资讯热点进行提取绘制成词云图。
​    考生通过数据绘制出词云图，可以清楚的了解到近年来院校关注的重点是什么，以及近年来考研相关的国家政策热点，借助这些信息，能够帮助到我们广大考生进行更好选择所需要关注的热点信息，更为方便的了解到国家政策。"
          
          >
          
            <img src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/logo/128/weibo.png">
          
        </a>
      
    
  </div>
</div>



        
      
    </div>
  </section>


        
        
          <div class="prev-next">
            
            
              <a class='next' href='/2019/04/02/%E4%BD%BF%E7%94%A8pyecharts%E7%BB%98%E5%88%B6heatmap/'>
                <p class='title'>使用pyecharts绘制heatmap<i class="fas fa-chevron-right" aria-hidden="true"></i></p>
                <p class='content'>实现效果
准备步骤首先需要安装pyecharts库以及地图库在上一篇文章中已经教大家安装了传送门:Anaconda安装pyecharts可视化界面库

大家可以参考一下官方文档:heatmap
...</p>
              </a>
            
          </div>
        
      </section>
    </article>
  

  
    <!-- 显示推荐文章和评论 -->



  <article class="post white-box reveal comments shadow">
    <section class="article typo">
      <p ct><i class='fas fa-comments'></i> 评论</p>
      
      
      
      
      
      
      
      
        <section id="comments">
          <div id="utterances">
            <script src="https://utteranc.es/client.js"
                    repo="sbtobb/sbtobb.github.io"
                    issue-term="title"
                    label="💬Comments"
                    theme="github-light"
                    crossorigin="anonymous"
                    async>
                  </script>
          </div>
        </section>
      
    </section>
  </article>


  




<!-- 根据页面mathjax变量决定是否加载MathJax数学公式js -->



  <script>
    window.subData = {
      title: '考研咨询政策数据挖掘',
      tools: true
    }
  </script>


</div>
<aside class='l_side'>
  
  

  
    
    


  <section class="widget toc-wrapper shadow desktop mobile">
    
  <header>
    
      <i class="fas fa-list fa-fw" aria-hidden="true"></i><span class='name'>本文目录</span>
    
  </header>


    <div class='content'>
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-研究背景及目的"><span class="toc-text">1 研究背景及目的</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-背景"><span class="toc-text">1.1 背景</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-考研资讯政策数据资源"><span class="toc-text">1.2 考研资讯政策数据资源</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-考研资讯政策数据挖掘目的和意义"><span class="toc-text">1.3 考研资讯政策数据挖掘目的和意义</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-考研资讯政策数据挖掘系统设计"><span class="toc-text">2 考研资讯政策数据挖掘系统设计</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-系统总体设计"><span class="toc-text">2.1 系统总体设计</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-1-系统设计目标"><span class="toc-text">2.1.1 系统设计目标</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-2-总体流程图"><span class="toc-text">2.1.2 总体流程图</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-系统功能模块设计"><span class="toc-text">2.2 系统功能模块设计</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-1-数据抓取模块设计"><span class="toc-text">2.2.1 数据抓取模块设计</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-2-数据解析模块设计"><span class="toc-text">2.2.2 数据解析模块设计</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-3-数据保存模块设计"><span class="toc-text">2.2.3 数据保存模块设计</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-4-数据导入模块设计"><span class="toc-text">2.2.4 数据导入模块设计</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-5-构建语料库模块设计"><span class="toc-text">2.2.5 构建语料库模块设计</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-6-中文分词模块设计"><span class="toc-text">2.2.6 中文分词模块设计</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-7-词频统计模块设计"><span class="toc-text">2.2.7 词频统计模块设计</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-系统实现"><span class="toc-text">3 系统实现</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-数据抓取"><span class="toc-text">3.1 数据抓取</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-数据解析"><span class="toc-text">3.2 数据解析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-数据保存"><span class="toc-text">3.3 数据保存</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-数据导入"><span class="toc-text">3.4 数据导入</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-5-数据预处理"><span class="toc-text">3.5 数据预处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-6-文本关键词模型的构建"><span class="toc-text">3.6 文本关键词模型的构建</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-7-文本关键词模型的训练"><span class="toc-text">3.7 文本关键词模型的训练</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-系统测试分析"><span class="toc-text">4 系统测试分析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-数据爬取"><span class="toc-text">4.1 数据爬取</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-总体分析"><span class="toc-text">4.2 总体分析</span></a></li></ol></li></ol>
    </div>
  </section>


  


</aside>


  
  <footer class="clearfix">
    <br><br>
    
      
        <br>
        <div class="social-wrapper">
          
            
              <a href="mailto:tobbcyg@gmail.com"
                class="social fas fa-envelope flat-btn"
                target="_blank"
                rel="external nofollow noopener noreferrer">
              </a>
            
          
            
              <a href="https://github.com/sbtobb"
                class="social fab fa-github flat-btn"
                target="_blank"
                rel="external nofollow noopener noreferrer">
              </a>
            
          
        </div>
      
    
      
        <div><p>Blog content follows the <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" target="_blank" rel="noopener">Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License</a></p>
</div>
      
    
      
        Use
        <a href="https://volantis.js.org/" target="_blank" class="codename">Volantiss</a>
        as theme, total visits
          <span id="busuanzi_value_site_pv"><i class="fas fa-circle-notch fa-spin fa-fw" aria-hidden="true"></i></span>
          times
        
      
    
      
        
          <div><p><a href="https://www.upyun.com/league" target="_blank" rel="noopener"><img src="https://cdn.jsdelivr.net/gh/sbtobb/CDN/blog/upaiyun_logo.png" style="zoom: 22%;" /></a></p>
</div>
        
      
    
      
        
          <div><p><a href="http://beian.miit.gov.cn/" target="_blank" rel="noopener">桂ICP备17012097号</a></p>
</div>
        
      
    
      
        <div class='copyright'>
        <p><a href="https://blog.chenyouguang.cn">Copyright © 2017-2020 CyouGuang</a></p>

        </div>
      
    
  </footer>

<script>setLoadingBarProgress(80);</script>


      <script>setLoadingBarProgress(60);</script>
    </div>
    <a class="s-top fas fa-arrow-up fa-fw" href='javascript:void(0)'></a>
  </div>
  
<script src="https://cdn.jsdelivr.net/npm/jquery@3.4/dist/jquery.min.js"></script>


  <script>
    
    var SEARCH_SERVICE = "hexo" || "hexo";
    var ROOT = "/" || "/";
    if (!ROOT.endsWith('/')) ROOT += '/';
  </script>


  <script async src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-volantis@2/js/instant_page.js" type="module" defer integrity="sha384-OeDn4XE77tdHo8pGtE1apMPmAipjoxUQ++eeJa6EtJCfHlvijigWiJpD7VDPWXV1"></script>


  <script src="https://cdn.jsdelivr.net/npm/scrollreveal@4.0.6/dist/scrollreveal.min.js"></script>
  <script type="text/javascript">
    $(function() {
      ScrollReveal().reveal('.l_main .reveal', {
        distance: '8px',
        duration: '800',
        interval: '100',
        scale: '1'
      });
    });
  </script>


  
<script src="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.js"></script>

  <script type="text/javascript">
    $(function() {
      Waves.attach('.flat-btn', ['waves-button']);
      Waves.attach('.float-btn', ['waves-button', 'waves-float']);
      Waves.attach('.float-btn-light', ['waves-button', 'waves-float', 'waves-light']);
      Waves.attach('.flat-box', ['waves-block']);
      Waves.attach('.float-box', ['waves-block', 'waves-float']);
      Waves.attach('.waves-image');
      Waves.init();
    });
  </script>


  <script defer src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-busuanzi@2.3/js/busuanzi.pure.mini.js"></script>



  
  
  
    
<script src="https://cdn.jsdelivr.net/npm/jquery-backstretch@2.1.18/jquery.backstretch.min.js"></script>

    <script type="text/javascript">
      $(function(){
        var imgs=["https://cdn.jsdelivr.net/gh/xaoxuu/cdn-wallpaper/abstract/41F215B9-261F-48B4-80B5-4E86E165259E.jpeg"];
        if ('true' == 'true') {
          function shuffle(arr){
            /*From countercurrent-time*/
            var n = arr.length;
            while(n--) {
              var index = Math.floor(Math.random() * n);
              var temp = arr[index];
              arr[index] = arr[n];
              arr[n] = temp;
            }
          }
          shuffle(imgs);
        }
        if ('.cover') {
          $('.cover').backstretch(
            imgs,
          {
            duration: "20000",
            fade: "1500"
          });
        } else {
          $.backstretch(
            imgs,
          {
            duration: "20000",
            fade: "1500"
          });
        }
      });
    </script>
  



  
    
<script src="https://cdn.jsdelivr.net/npm/aplayer@1.10/dist/APlayer.min.js"></script>

  
    
<script src="https://cdn.jsdelivr.net/npm/meting@2.0/dist/Meting.min.js"></script>

  














  
<script src="/js/app.js"></script>



  
<script src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-volantis@2.6.5/js/search.js"></script>



  
<script src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-volantis@2/js/comment_typing.js"></script>








<!-- 复制 -->

  <script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="fas fa-copy"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('fa-copy');
        $icon.addClass('fa-check-circle');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('fa-check-circle');
          $icon.addClass('fa-copy');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('fa-copy');
        $icon.addClass('fa-times-circle');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('fa-times-circle');
          $icon.addClass('fa-copy');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>




<!-- fancybox -->
<script src="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>
<script>
  function pjax_fancybox() {
    $(".article-entry").find("img").not('.inline').not('a img').each(function () { //渲染 fancybox
      var element = document.createElement("a"); // a 标签
      $(element).attr("pjax-fancybox", "");  // 过滤 pjax
      $(element).attr("href", $(this).attr("src"));
      if ($(this).attr("data-original")) {
        $(element).attr("href", $(this).attr("data-original"));
      }
      $(element).attr("data-fancybox", "images");
      var caption = "";   // 描述信息
      if ($(this).attr('alt')) {  // 标准 markdown 描述信息
        $(element).attr('data-caption', $(this).attr('alt'));
        caption = $(this).attr('alt');
      }
      var div = document.createElement("div");
      $(div).addClass("fancybox");
      $(this).wrap(div); // 最外层套 div ，其实主要作用还是 class 样式
      var span = document.createElement("span");
      $(span).addClass("image-caption");
      $(span).text(caption); // 加描述
      $(this).after(span);  // 再套一层描述
      $(this).wrap(element);  // 最后套 a 标签
    })
    $(".article-entry").find("img").fancybox({
      selector: '[data-fancybox="images"]',
      hash: false,
      loop: false,
      closeClick: true,
      helpers: {
        overlay: {closeClick: true}
      },
      buttons: [
        "zoom",
        "close"
      ]
    });
  };
  $(function () {
    pjax_fancybox();
  });
</script>




  <script>setLoadingBarProgress(100);</script>
</body>
</html>
